# Definitions
As the sample size increases, the sample proportion will tend towards a normal distribution

## Point estimates
A point estimate $p$ is something like an average or standard deviation. It cannot be knwon without sampling the whole population. $\hat{p}$ represents the point estimate of the sample

## Sampling error
The variance between the estimates generated by repeating an experiment.

## Bias
An error that offsets results in one direction

# Central limit theorem
![[Central Limit Theorem]]

# Confidence interval
1.96 is a significant number because it's the number of standard deviations away from the mean that wraps 95% of the data.

90%: 1.65
95%: 1.96
99%: 2.58

You have to check [[#Central Limit Theorem#Conditions|CLT conditions]] before doing this formally

## Formulae
95% confidence interval:
	$\hat{p} \pm 1.96 \times SE$

General form:
	$\hat{p} \pm z^* \times SE$
		where 
		$z^*$ is the confidence level

$z^* \times SE$ is also known as the margin of error

# Estimating sample size
Assume $p$ is 0.5 and solve for $n$:
$z^* \times \sqrt{\frac{p(1-p)}{n}} < \textrm{margin of error}$

# Two $p$s
You can look at the difference between two proportions
$$SE=\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}$$
The confidence interval version:
$$\hat{p}_1 - \hat{p}_2 \pm z^* \sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}$$

# Monte Carlo
- Problem: it can be difficult to compute the [[Predictions#Expected Value|expected value]] of a continuous random variable
- Solution: approximate the expected value by repeatedly sampling from the distribution
	- Usually by simulating

$$\mathcal{E}(g(X)) = \int_{x}f_{X}(x) \cdot g(x) dx \approx \frac{1}{N} \sum\limits_{i = 1}^{N} g(x_{i})$$

See also:
- [[Probability Distribution#Probability density function|Probability density functions]]